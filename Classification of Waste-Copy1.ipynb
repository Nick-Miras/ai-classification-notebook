{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94778c77",
   "metadata": {},
   "source": [
    "# Import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1d86b82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T12:45:54.705146Z",
     "iopub.status.busy": "2024-03-20T12:45:54.704759Z",
     "iopub.status.idle": "2024-03-20T12:46:00.170155Z",
     "shell.execute_reply": "2024-03-20T12:46:00.168718Z",
     "shell.execute_reply.started": "2024-03-20T12:45:54.705102Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc3a502",
   "metadata": {},
   "source": [
    "# Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "988f4d00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T12:46:00.172702Z",
     "iopub.status.busy": "2024-03-20T12:46:00.172060Z",
     "iopub.status.idle": "2024-03-20T12:46:03.514425Z",
     "shell.execute_reply": "2024-03-20T12:46:03.513614Z",
     "shell.execute_reply.started": "2024-03-20T12:46:00.172673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5078 files belonging to 9 classes.\n",
      "Using 4571 files for training.\n",
      "Found 5078 files belonging to 9 classes.\n",
      "Using 507 files for validation.\n"
     ]
    }
   ],
   "source": [
    "DIR = \"images/datasets/2/\"\n",
    "\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(DIR, validation_split=0.1, \n",
    "                                                                    subset=\"training\", seed=42, \n",
    "                                                                    batch_size=16, smart_resize=True)\n",
    "\n",
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(DIR, validation_split=0.1,\n",
    "                                                                  subset=\"validation\", seed=42,\n",
    "                                                                  batch_size=16, smart_resize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316938a8",
   "metadata": {},
   "source": [
    "### Optimise the training and testing performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68e7c06d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T12:46:03.515653Z",
     "iopub.status.busy": "2024-03-20T12:46:03.515411Z",
     "iopub.status.idle": "2024-03-20T12:46:03.522560Z",
     "shell.execute_reply": "2024-03-20T12:46:03.521320Z",
     "shell.execute_reply.started": "2024-03-20T12:46:03.515628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aluminium', 'Carton', 'Glass', 'Organic Waste', 'Other Plastics', 'Paper and Cardboard', 'Plastic', 'Textiles', 'Wood'] 9\n"
     ]
    }
   ],
   "source": [
    "classes = train_dataset.class_names\n",
    "numClasses = len(train_dataset.class_names)\n",
    "print(classes, numClasses)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee92305",
   "metadata": {},
   "source": [
    "### Performing Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd11923b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T12:46:03.526766Z",
     "iopub.status.busy": "2024-03-20T12:46:03.525578Z",
     "iopub.status.idle": "2024-03-20T12:46:03.566495Z",
     "shell.execute_reply": "2024-03-20T12:46:03.565524Z",
     "shell.execute_reply.started": "2024-03-20T12:46:03.526728Z"
    }
   },
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "])\n",
    "\n",
    "preprocess_input = tf.keras.applications.inception_v3.preprocess_input\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045b44e8",
   "metadata": {},
   "source": [
    "# MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fea1a1",
   "metadata": {},
   "source": [
    "### Resnet152 Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7403dbc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T12:46:03.567943Z",
     "iopub.status.busy": "2024-03-20T12:46:03.567642Z",
     "iopub.status.idle": "2024-03-20T12:49:21.556295Z",
     "shell.execute_reply": "2024-03-20T12:49:21.555150Z",
     "shell.execute_reply.started": "2024-03-20T12:46:03.567917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "234698864/234698864 [==============================] - 6s 0us/step\n",
      "Epoch 1/10\n",
      "286/286 [==============================] - 78s 220ms/step - loss: 0.8630 - accuracy: 0.7587 - val_loss: 0.4245 - val_accuracy: 0.8738\n",
      "Epoch 2/10\n",
      "286/286 [==============================] - 55s 190ms/step - loss: 0.1297 - accuracy: 0.9608 - val_loss: 0.4552 - val_accuracy: 0.8619\n",
      "Epoch 3/10\n",
      "286/286 [==============================] - 55s 190ms/step - loss: 0.0485 - accuracy: 0.9858 - val_loss: 0.4371 - val_accuracy: 0.8935\n"
     ]
    }
   ],
   "source": [
    "baseModel = tf.keras.applications.ResNet152(input_shape=(256, 256, 3), weights='imagenet',\n",
    "                                           include_top=False, classes=numClasses)\n",
    "\n",
    "for layers in baseModel.layers:\n",
    "    layers.trainable=False\n",
    "    \n",
    "last_output = baseModel.layers[-1].output\n",
    "\n",
    "x = tf.keras.layers.Dropout(0.5)(last_output)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(numClasses, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=baseModel.input, outputs=x)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "                        loss=loss,\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "epochs=10\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "history = model.fit(train_dataset, validation_data=test_dataset, epochs=epochs, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd43538",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05fafc04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T12:49:21.559385Z",
     "iopub.status.busy": "2024-03-20T12:49:21.558347Z",
     "iopub.status.idle": "2024-03-20T12:49:21.564254Z",
     "shell.execute_reply": "2024-03-20T12:49:21.562829Z",
     "shell.execute_reply.started": "2024-03-20T12:49:21.559354Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.plot(range(0, epochs), history.history[\"loss\"], color=\"b\", label=\"Loss\")\n",
    "# plt.plot(range(0, epochs), history.history[\"val_loss\"], color=\"r\", label=\"Test Loss\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d0083fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T12:49:21.566391Z",
     "iopub.status.busy": "2024-03-20T12:49:21.566114Z",
     "iopub.status.idle": "2024-03-20T12:49:21.571647Z",
     "shell.execute_reply": "2024-03-20T12:49:21.569983Z",
     "shell.execute_reply.started": "2024-03-20T12:49:21.566348Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.plot(range(0, epochs), history.history[\"accuracy\"], color=\"b\", label=\"Accuracy\")\n",
    "# plt.plot(range(0, epochs), history.history[\"val_accuracy\"], color=\"r\", label=\"Test Accuracy\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9172fe3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T12:49:21.574118Z",
     "iopub.status.busy": "2024-03-20T12:49:21.573725Z",
     "iopub.status.idle": "2024-03-20T12:49:21.579576Z",
     "shell.execute_reply": "2024-03-20T12:49:21.577888Z",
     "shell.execute_reply.started": "2024-03-20T12:49:21.574081Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.xlim([0, 0.003])\n",
    "# learning_rates = 1e-3 * (10 ** (np.arange(epochs) / 30))\n",
    "# plt.plot(learning_rates, history.history['loss'], lw=3, color='#48e073')\n",
    "# plt.title('Learning rate vs. loss', size=20)\n",
    "# plt.xlabel('Learning rate', size=14)\n",
    "# plt.ylabel('Loss', size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398970ff",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9bf2f55-1934-4072-9505-6fa7f75403c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T12:49:21.581579Z",
     "iopub.status.busy": "2024-03-20T12:49:21.581155Z",
     "iopub.status.idle": "2024-03-20T12:49:23.614564Z",
     "shell.execute_reply": "2024-03-20T12:49:23.613721Z",
     "shell.execute_reply.started": "2024-03-20T12:49:21.581541Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eec45c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T12:49:23.618174Z",
     "iopub.status.busy": "2024-03-20T12:49:23.617872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 21.  16.  20.]\n",
      "  [ 21.  16.  20.]\n",
      "  [ 19.  14.  18.]\n",
      "  ...\n",
      "  [ 16.  11.  15.]\n",
      "  [ 18.  13.  17.]\n",
      "  [ 17.  15.  18.]]\n",
      "\n",
      " [[ 19.  14.  20.]\n",
      "  [ 15.  13.  18.]\n",
      "  [ 16.  14.  19.]\n",
      "  ...\n",
      "  [ 18.  16.  19.]\n",
      "  [ 17.  15.  18.]\n",
      "  [ 17.  15.  18.]]\n",
      "\n",
      " [[ 17.  15.  18.]\n",
      "  [ 19.  14.  20.]\n",
      "  [ 17.  15.  20.]\n",
      "  ...\n",
      "  [ 19.  14.  20.]\n",
      "  [ 17.  15.  18.]\n",
      "  [ 15.  15.  15.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[112. 107. 103.]\n",
      "  [112. 109. 102.]\n",
      "  [119. 116. 111.]\n",
      "  ...\n",
      "  [ 66.  62.  59.]\n",
      "  [ 67.  63.  60.]\n",
      "  [ 64.  60.  59.]]\n",
      "\n",
      " [[111. 108. 103.]\n",
      "  [115. 112. 107.]\n",
      "  [110. 107. 100.]\n",
      "  ...\n",
      "  [ 69.  65.  62.]\n",
      "  [ 67.  63.  62.]\n",
      "  [ 67.  63.  60.]]\n",
      "\n",
      " [[103. 100.  95.]\n",
      "  [111. 108. 103.]\n",
      "  [255. 255. 248.]\n",
      "  ...\n",
      "  [ 67.  63.  60.]\n",
      "  [ 65.  61.  60.]\n",
      "  [ 62.  58.  55.]]]\n",
      "=============\n",
      "tf.Tensor(\n",
      "[[[[ 21.  16.  20.]\n",
      "   [ 21.  16.  20.]\n",
      "   [ 19.  14.  18.]\n",
      "   ...\n",
      "   [ 16.  11.  15.]\n",
      "   [ 18.  13.  17.]\n",
      "   [ 17.  15.  18.]]\n",
      "\n",
      "  [[ 19.  14.  20.]\n",
      "   [ 15.  13.  18.]\n",
      "   [ 16.  14.  19.]\n",
      "   ...\n",
      "   [ 18.  16.  19.]\n",
      "   [ 17.  15.  18.]\n",
      "   [ 17.  15.  18.]]\n",
      "\n",
      "  [[ 17.  15.  18.]\n",
      "   [ 19.  14.  20.]\n",
      "   [ 17.  15.  20.]\n",
      "   ...\n",
      "   [ 19.  14.  20.]\n",
      "   [ 17.  15.  18.]\n",
      "   [ 15.  15.  15.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[112. 107. 103.]\n",
      "   [112. 109. 102.]\n",
      "   [119. 116. 111.]\n",
      "   ...\n",
      "   [ 66.  62.  59.]\n",
      "   [ 67.  63.  60.]\n",
      "   [ 64.  60.  59.]]\n",
      "\n",
      "  [[111. 108. 103.]\n",
      "   [115. 112. 107.]\n",
      "   [110. 107. 100.]\n",
      "   ...\n",
      "   [ 69.  65.  62.]\n",
      "   [ 67.  63.  62.]\n",
      "   [ 67.  63.  60.]]\n",
      "\n",
      "  [[103. 100.  95.]\n",
      "   [111. 108. 103.]\n",
      "   [255. 255. 248.]\n",
      "   ...\n",
      "   [ 67.  63.  60.]\n",
      "   [ 65.  61.  60.]\n",
      "   [ 62.  58.  55.]]]], shape=(1, 256, 256, 3), dtype=float32)\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "[8.6735731e-01 4.2034371e-04 2.2325075e-04 1.1727641e-01 5.4925572e-06\n",
      " 9.8768845e+01 2.4378356e-01 3.3363263e-04 1.7622189e-03] \n",
      " ['Aluminium', 'Carton', 'Glass', 'Organic Waste', 'Other Plastics', 'Paper and Cardboard', 'Plastic', 'Textiles', 'Wood']\n",
      "Prediction:  Paper and Cardboard 98.76884818077087%\n"
     ]
    }
   ],
   "source": [
    "# url = \"https://images.unsplash.com/photo-1577705998148-6da4f3963bc8?ixid=MnwxMjA3fDB8MHxzZWFyY2h8Nnx8Y2FyZGJvYXJkfGVufDB8fDB8fA%3D%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=500&q=60\"\n",
    "# image = tf.keras.utils.get_file(\"images/paper.jpeg\", origin=url)\n",
    "\n",
    "img = tf.keras.preprocessing.image.load_img(\"images/biodegradable/paper.jpeg\", target_size=(256, 256))\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "print(img_array)\n",
    "img_array = tf.expand_dims(img_array, 0) \n",
    "print(\"=============\")\n",
    "print(img_array)\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "#score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "plt.imshow(img)\n",
    "# print(predictions)\n",
    "# print(\"Prediction: \" + str(classes[np.argmax(predictions)]))\n",
    "print(predictions[0]*100, \"\\n\", classes)\n",
    "print(\"Prediction: \", classes[np.argmax(predictions)], f\"{predictions[0][np.argmax(predictions)]*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b05c5b3-da02-43a8-9571-7b60e189925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    'images',\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    batch_size=None\n",
    ")\n",
    "\n",
    "def add_batch_dimension(image):\n",
    "  # Expand the dimension at index 0 (beginning)\n",
    "  return tf.expand_dims(image, axis=0)\n",
    "\n",
    "print(images.class_names)\n",
    "images_ds = images_ds.map(add_batch_dimension)\n",
    "predictions = model.predict(images_ds)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964bf962-7f6f-470a-8bb8-bea0f02b05e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = tf.keras.utils.image_dataset_from_directory(\n",
    "    'images',\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    batch_size=None\n",
    ")\n",
    "print(images.class_names)\n",
    "for element in images:\n",
    "    print(element)\n",
    "    img_array = tf.expand_dims(element, 0)\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "    #score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "    plt.imshow(img)\n",
    "    # print(predictions)\n",
    "    # print(\"Prediction: \" + str(classes[np.argmax(predictions)]))\n",
    "    print(predictions[0]*100, \"\\n\", classes)\n",
    "    print(\"Prediction: \", classes[np.argmax(predictions)], f\"{predictions[0][np.argmax(predictions)]*100}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
